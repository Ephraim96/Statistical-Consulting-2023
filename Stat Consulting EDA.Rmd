---
title: "Stat Consulting EDA"
author: "Ephraim Romesberg"
date: "2/4/2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
LavaFlow <- read.csv("Data/XRF_WesternColumbiaRiverGorgeCRBG.csv")
repeats=LavaFlow$AlternateSampleID!="null"
library(MASS)
library(grt)
library(VGAM)
library(ggplot2)
library(forcats)
library(caret)
library(dplyr)
library(nnet)
library(glmnet)
library(cowplot)
```

## Exploratory Data Analysis:

```{r}
#checking how many NA's in each column
noNA=sapply(colnames(LavaFlow),function(x){sum(is.na(LavaFlow[x]))})
Lavaflow1=LavaFlow[,noNA==0]
View(Lavaflow1)
#removing repeated samples
Lavaflow1=Lavaflow1[Lavaflow1$AlternateSampleID=="null",]
#names of predictors used
predictors1=colnames(Lavaflow1)[4:25]
#data matrix of predictors
Lavaflow1.X=Lavaflow1[,predictors1]
sigma1=cov(Lavaflow1.X)
pca1=eigen(sigma1)

#portion of total variance explained by first k principal components 
round(cumsum(pca1$values)/sum(pca1$values),5)
bp=barplot(names.arg=as.character(1:5),height=(cumsum(pca1$values)/sum(pca1$values))[1:5],ylim = c(0,1),xlab = "k",col = "red")
title(main="Portion of total variance explained by first k principal components")
text(bp,round(cumsum(pca1$values)/sum(pca1$values),3)[1:5]/2,labels=round(cumsum(pca1$values)/sum(pca1$values),3)[1:5])

#Correlation of principal components with variables:
r.pca1=diag(sqrt(pca1$values))%*%t(pca1$vectors)%*%diag(1/sqrt(diag(sigma1)))
colnames(r.pca1)=colnames(sigma1)
round(r.pca1[1:5,],3)

#First two principal components of data
pca.2=data.frame(data.matrix(Lavaflow1.X)%*%pca1$vectors[,1:2])
pca.2$MapUnit=Lavaflow1$MapUnit
ggplot(pca.2,aes(x=X1,y=X2,color=MapUnit))+geom_point()
```


```{r}
table(Lavaflow1$MapUnit)
#Some groups only have one observation

#Linear Discriminant Analysis
lda1=lda(x=Lavaflow1.X,grouping=Lavaflow1$MapUnit,prior=rep(1/22,22))
lda1.cv=lda(x=Lavaflow1.X,grouping=Lavaflow1$MapUnit,prior=rep(1/22,22),CV=TRUE)
table(lda1.cv$class,Lavaflow1$MapUnit)
#portion of accurately classified observations 
sum(diag(table(lda1.cv$class,Lavaflow1$MapUnit)))/sum(table(lda1.cv$class,Lavaflow1$MapUnit))

#First two discriminants of data
discrim2=data.frame(data.matrix(Lavaflow1.X)%*%lda1$scaling[,1:2])
discrim2$MapUnit=Lavaflow1$MapUnit
dmeans=data.frame(lda1$means%*%lda1$scaling[,1:2])
ggplot(data=discrim2,aes(x=LD1,y=LD2))+geom_point(aes(color=MapUnit))+geom_text(data=dmeans,aes(x=LD1,y=LD2,label=1:22))+labs(title="First two linear discriminants of data")

#Correlation of discriminants with variables:
cor(data.frame(data.matrix(Lavaflow1.X)%*%lda1$scaling[,1:2]),Lavaflow1.X)
```

```{r}
#combining Tggc with Tggc-h and Tgo with Tgo-h
Lavaflow2=Lavaflow1
Lavaflow2$MapUnit=fct_collapse(Lavaflow2$MapUnit,Tggc2=c("Tggc","Tggc-h"),Tgo2=c("Tgo","Tgo-h"))
table(Lavaflow2$MapUnit)
#deleting groups which have less than 5 observations
lev=levels(Lavaflow2$MapUnit)[table(Lavaflow2$MapUnit)<5]
Lavaflow2=Lavaflow2[!(Lavaflow2$MapUnit%in%lev),]
Lavaflow2$MapUnit=factor(Lavaflow2$MapUnit)
#Now we have 16 total groups
table(Lavaflow2$MapUnit)
#data matrix of predictors
Lavaflow2.X=Lavaflow2[,predictors1]
```

```{r}
#standardizing
Lavaflow2.X.Z=data.frame(scale(Lavaflow2.X))
```

## Linear Discriminant Analysis:

```{r}
#Linear Discriminant Analysis using (standardized) Lavaflow2 (no groups with less than 5 observations/combined Tggc with Tggc-h and Tgo with Tgo-h)
lda2=lda(x=Lavaflow2.X.Z,grouping=Lavaflow2$MapUnit,prior=rep(1/16,16))
lda2.cv=lda(x=Lavaflow2.X.Z,grouping=Lavaflow2$MapUnit,prior=rep(1/16,16),CV=TRUE)
table(lda2.cv$class,Lavaflow2$MapUnit)

#portion of accurately classified observations 
sum(diag(table(lda2.cv$class,Lavaflow2$MapUnit)))/sum(table(lda2.cv$class,Lavaflow2$MapUnit))

#First two discriminants of data
discrim22=data.frame(data.matrix(Lavaflow2.X.Z)%*%lda2$scaling[,1:2])
discrim22$MapUnit=Lavaflow2$MapUnit
dmeans2=data.frame(lda2$means%*%lda2$scaling[,1:2])
ggplot(data=discrim22,aes(x=LD1,y=LD2))+geom_point(aes(color=MapUnit))+geom_text(data=dmeans2,aes(x=LD1,y=LD2,label=1:16))+labs(title="First two linear discriminants of data")

#Correlation of discriminants with variables:
cor(data.frame(data.matrix(Lavaflow2.X.Z)%*%lda2$scaling[,1:2]),Lavaflow2.X.Z)

```


```{r}
#Correlation of discriminants with variables (ungrouped):
cor.lda2.u=cor(data.frame(data.matrix(Lavaflow2.X.Z)%*%lda2$scaling),Lavaflow2.X.Z)
max.ind.u=apply(abs(cor.lda2.u),MARGIN = 1,which.max)
max.cor.lda2.u=data.frame(LD=names(max.ind.u),predictor=colnames(cor.lda2.u)[max.ind.u],correlation=sapply(1:15,function(i){cor.lda2.u[i,max.ind.u[i]]}))
max.cor.lda2.u

#It looks like P2O5 and MgO play the biggest role in classification
ggplot(data=data.frame(Lavaflow2.X.Z,MapUnit=Lavaflow2$MapUnit),aes(x=P2O5,y=MgO,color=MapUnit))+geom_point()
```


```{r,include=FALSE,echo=FALSE}
#grouped correlation of discriminants with variables
cor.lda2=matrix(nrow = 15,ncol = 22)
lda2.LD=data.matrix(Lavaflow2.X.Z)%*%lda2$scaling
for (i in 1:15){
  for (j in 1:22){
cor.lda2[i,j]=weighted.mean(summarize(group_by(data.frame(LD=lda2.LD[,i],Predictor=Lavaflow2.X.Z[,j],group=Lavaflow2$MapUnit),group),cor=cor(LD,Predictor))$cor,w=table(Lavaflow2$MapUnit))
    
    }
}
colnames(cor.lda2)=colnames(Lavaflow2.X.Z)
rownames(cor.lda2)=colnames(lda2.LD)
#cor.lda2=cor(data.frame(data.matrix(Lavaflow2.X.Z)%*%lda2$scaling),Lavaflow2.X.Z)
max.ind=apply(abs(cor.lda2),MARGIN = 1,which.max)
max.cor.lda2=data.frame(LD=names(max.ind),predictor=colnames(cor.lda2)[max.ind],correlation=sapply(1:15,function(i){cor.lda2[i,max.ind[i]]}))
max.cor.lda2
```


```{r}
#Function for Repeated random sub-sampling cross-validation for classification using the first N.LD linear discriminants (repeated N.resamp times)

LDA.CV=function(N.LD,data=Lavaflow2.X,groups=Lavaflow2$MapUnit,p.test=1/3,N.resamp=50){
  groups=factor(groups)
  ngrp=length(levels(groups))
  min.dist=function(x,means){
    dists=rep(NA,nrow(means))
    for (i in 1:nrow(means)){
      dists[i]=sum((x-means[i,])^2)
    }
    return(rownames(means)[which.min(dists)])
  }
  confusion=vector(mode = "list",length=N.resamp)
  for (i in 1:N.resamp){
    test=slice_sample(group_by(data.frame(data,groups),groups),prop = p.test)
    train=anti_join(group_by(data.frame(data,groups),groups),test,by=names(test))
    ppv=preProcess(as.data.frame(train[,names(train)%in%names(data)]),method = c("center", "scale"))
    train.z = predict(ppv, as.data.frame(train[,names(train)%in%names(data)]))
    test.z = predict(ppv, as.data.frame(test[,names(test)%in%names(data)]))
    train.groups=train$groups
    test.groups=test$groups
    lda.s=lda(x=train.z,grouping=train.groups,prior=rep(1/ngrp,ngrp))
    ld.coef=lda.s$scaling[,1:N.LD]
    ld.means=lda.s$means%*%ld.coef
    ld.test=data.matrix(test.z)%*%ld.coef
    predictions=apply(ld.test,MARGIN = 1,function(x){min.dist(x,means = ld.means)})
    predictions=factor(predictions,levels=levels(groups))
    confusion[[i]]=table(test.groups,predictions)
  }
  accuracy=sapply(confusion,function(x){sum(diag(x))/sum(x)})
  return(list("confusion.matrices"=confusion,"accuracy"=accuracy))
}
```


```{r,cache=TRUE}
set.seed(5)
CV.all=sapply(1:15,function(i){LDA.CV(N.LD = i,p.test = 1/4)$accuracy})
```


```{r}
CV.mean=apply(CV.all,2,mean)
CV.quantile=t(apply(CV.all,2,function(x){quantile(x,c(.025,.975))}))
CV.sd=apply(CV.all,2,sd)
CV.data=data.frame(LD=1:15,accuracy.mean=CV.mean,accuracy.sd=CV.sd,q1=CV.quantile[,1],q2=CV.quantile[,2])

 ggplot(CV.data, aes(x=LD, y=accuracy.mean)) + 
  geom_bar(stat="identity", color="black",fill="red",width = .8) +
  geom_errorbar(aes(ymin=q1, ymax=q2),width=.2)+geom_text(aes(x=LD,y=accuracy.mean/2,label=round(accuracy.mean,2)))+labs(title="Mean Classification Accuracy Using the First k Discriminants", x="k", y = "Mean Classification Accuracy & 95% CI")+
   theme_classic() 

```


```{r}
#gives classification accuracy averages for each mapunit group using Repeated random sub-sampling cross-validation output

group.accuracy=function(CV,quant=c(.025,.975),transpose=FALSE){
  confusion=CV$confusion.matrices
  
  if (transpose){
    confusion=lapply(confusion,t)
  }
  
  total.accuracy=CV$accuracy
  n.grp=nrow(confusion[[1]])
  grp.names=rownames(confusion[[1]])
  accuracies=rbind(sapply(confusion,function(x){diag(x)/(x%*%matrix(rep(1,n.grp),ncol = 1))}),total.accuracy)
  mean.accuracies=apply(accuracies,MARGIN = 1,mean,na.rm=TRUE)
  q1=apply(accuracies,MARGIN = 1,function(x){quantile(x,quant[1],na.rm=TRUE)})
  q2=apply(accuracies,MARGIN = 1,function(x){quantile(x,quant[2],na.rm=TRUE)})
  accuracy=data.frame(group=c(grp.names,"Total"),mean.accuracies,q1,q2)
  return(accuracy)
  }
```


```{r,cache=TRUE}
set.seed(15)
LDA15.samp=LDA.CV(N.LD = 15,N.resamp = 100,p.test = 1/4)
```


```{r}
LDA15.samp2=group.accuracy(LDA15.samp,transpose = FALSE)
#LDA15.samp2

 ggplot(LDA15.samp2, aes(x=group, y=mean.accuracies)) + 
  geom_bar(stat="identity", color="black",fill="red",width = .8) +
  geom_errorbar(aes(ymin=q1, ymax=q2),width=.2)+geom_text(aes(x=group,y=mean.accuracies/2,label=round(mean.accuracies,2)))+geom_text(aes(x=group,y=-.05,label=c(table(Lavaflow2$MapUnit),sum(table(Lavaflow2$MapUnit)))))+labs(title="Mean Classification Accuracy For Observations in Each MapUnit (LDA)", x="MapUnit", y = "Mean Classification Accuracy & 95% CI")+
   theme_classic() + theme(axis.text.x = element_text(angle = 90, vjust = .5, hjust=1))

```


```{r}
LDA15.samp2t=group.accuracy(LDA15.samp,transpose = TRUE)
#LDA15.samp2t

 ggplot(LDA15.samp2t, aes(x=group, y=mean.accuracies)) + 
  geom_bar(stat="identity", color="black",fill="red",width = .8) +
  geom_errorbar(aes(ymin=q1, ymax=q2),width=.2)+geom_text(aes(x=group,y=mean.accuracies/2,label=round(mean.accuracies,2)))+geom_text(aes(x=group,y=-.05,label=c(table(Lavaflow2$MapUnit),sum(table(Lavaflow2$MapUnit)))))+labs(title="Mean Classification Accuracy For Observations Assigned to Each MapUnit (LDA)", x="MapUnit", y = "Mean Classification Accuracy & 95% CI")+
   theme_classic() + theme(axis.text.x = element_text(angle = 90, vjust = .5, hjust=1))

```

## PCA (using Standardized Lavaflow2):

```{r}
#PCA using Standardized Lavaflow2
sigma2=cov(Lavaflow2.X.Z)
pca2=eigen(sigma2)

#portion of total variance explained by first k principal components 
round(cumsum(pca2$values)/sum(pca2$values),5)
bp=barplot(names.arg=as.character(1:6),height=(cumsum(pca2$values)/sum(pca2$values))[1:6],ylim = c(0,1),xlab = "k",col = "red")
title(main="Portion of total variance explained by first k principal components")
text(bp,round(cumsum(pca2$values)/sum(pca2$values),3)[1:6]/2,labels=round(cumsum(pca2$values)/sum(pca2$values),3)[1:6])

#Correlation of principal components with variables:
r.pca2=diag(sqrt(pca2$values))%*%t(pca2$vectors)%*%diag(1/sqrt(diag(sigma2)))
colnames(r.pca2)=colnames(sigma2)
round(r.pca2[1:6,],3)

#First two principal components of data
pca.22=data.frame(data.matrix(Lavaflow2.X.Z)%*%pca2$vectors[,1:2])
pca.22$MapUnit=Lavaflow2$MapUnit
ggplot(pca.22,aes(x=X1,y=X2,color=MapUnit))+geom_point()

#First principal component of data
ggplot(pca.22,aes(x=X1,fill=MapUnit))+geom_density(kernel = "gaussian")+facet_grid(rows = vars(MapUnit))
```

## Multinomial Logistic Regression:


```{r,cache=TRUE,results='hide',message=FALSE,warning=FALSE}
#multinomial logistic regression:

Lavaflow2.mlr=Lavaflow2.X.Z
Lavaflow2.mlr$MapUnit=Lavaflow2$MapUnit
predictors2=colnames(Lavaflow2.mlr)[-23]
predictors2

mlr1=multinom(formula = as.formula(paste("MapUnit",paste0(predictors2,collapse = "+"),sep="~")),data = Lavaflow2.mlr)
mlr1.selection=stepAIC(mlr1,direction = "backward")
mlr1.selection2=stepAIC(multinom(formula = MapUnit~1,data = Lavaflow2.mlr),direction = "forward",scope=as.formula(paste("~",paste0(predictors2,collapse = "+"),sep = "")) )
```

```{r,cache=TRUE}
s1=summary(mlr1.selection)
s2=summary(mlr1.selection2)
```


```{r}
#model found using backward stepAIC selection:
#s1
#model found using forward stepAIC selection:
#s2

s1$AIC
s2$AIC

# Backward (Lowest AIC): multinom(formula = MapUnit ~ SiO2 + TiO2 + MgO + P2O5 + V + Cu +  Nb + Sr, data = Lavaflow2.mlr)

# forward: multinom(formula = MapUnit ~ TiO2 + Sc + Y + V + P2O5 + Sr + Cu, data = Lavaflow2.mlr)

#confusion matrix for backward selection:
confusion.backward=table(Lavaflow2.mlr$MapUnit,colnames(mlr1.selection$fitted.values)[apply(mlr1.selection$fitted.values,MARGIN = 1,which.max)])
confusion.backward
#accuracy for backward:
sum(diag(confusion.backward))/sum(confusion.backward)
#confusion matrix for forward selection:
confusion.forward=table(Lavaflow2.mlr$MapUnit,colnames(mlr1.selection2$fitted.values)[apply(mlr1.selection2$fitted.values,MARGIN = 1,which.max)])
confusion.forward
#accuracy for forward:
sum(diag(confusion.forward))/sum(confusion.forward)
```



```{r}
#Function for Repeated random sub-sampling cross-validation for classification using multinomial logistic regression (repeated N.resamp times)

MLR.CV=function(variables,data=Lavaflow2.X,groups=Lavaflow2$MapUnit,p.test=1/3,N.resamp=50){
  groups=factor(groups)
  confusion=vector(mode = "list",length=N.resamp)
  for (i in 1:N.resamp){
    test=slice_sample(group_by(data.frame(data,groups),groups),prop = p.test)
    train=anti_join(group_by(data.frame(data,groups),groups),test,by=names(test))
    ppv=preProcess(as.data.frame(train[,names(train)%in%names(data)]),method = c("center", "scale"))
    train.z = predict(ppv, as.data.frame(train[,names(train)%in%names(data)]))
    test.z = predict(ppv, as.data.frame(test[,names(test)%in%names(data)]))
    train.z$groups=train$groups
    test.z$groups=test$groups
    mlr.s=multinom(formula = as.formula(paste("groups",paste0(variables,collapse = "+"),sep="~")),data = train.z)
    predictions=predict(mlr.s,newdata=test.z)
    confusion[[i]]=table(test.groups=test.z$groups,predictions)
  }
  accuracy=sapply(confusion,function(x){sum(diag(x))/sum(x)})
  return(list("confusion.matrices"=confusion,"accuracy"=accuracy))
}
```



```{r,cache=TRUE,results='hide',message=FALSE,warning=FALSE}
set.seed(12)
mlr.cv1=MLR.CV(variables = c("SiO2","TiO2","MgO","P2O5","V","Cu","Nb","Sr"),N.resamp = 100,p.test = 1/4)
```


```{r}
mlr.cv12=group.accuracy(mlr.cv1,transpose = FALSE)
#mlr.cv12

 ggplot(mlr.cv12, aes(x=group, y=mean.accuracies)) + 
  geom_bar(stat="identity", color="black",fill="red",width = .8) +
  geom_errorbar(aes(ymin=q1, ymax=q2),width=.2)+geom_text(aes(x=group,y=mean.accuracies/2,label=round(mean.accuracies,2)))+geom_text(aes(x=group,y=-.05,label=c(table(Lavaflow2$MapUnit),sum(table(Lavaflow2$MapUnit)))))+labs(title="Mean Classification Accuracy For Observations in Each MapUnit (MLR)", x="MapUnit", y = "Mean Classification Accuracy & 95% CI")+
   theme_classic() + theme(axis.text.x = element_text(angle = 90, vjust = .5, hjust=1))

```


```{r}
mlr.cv12t=group.accuracy(mlr.cv1,transpose = TRUE)
#mlr.cv12t

 ggplot(mlr.cv12t, aes(x=group, y=mean.accuracies)) + 
  geom_bar(stat="identity", color="black",fill="red",width = .8) +
  geom_errorbar(aes(ymin=q1, ymax=q2),width=.2)+geom_text(aes(x=group,y=mean.accuracies/2,label=round(mean.accuracies,2)))+geom_text(aes(x=group,y=-.05,label=c(table(Lavaflow2$MapUnit),sum(table(Lavaflow2$MapUnit)))))+labs(title="Mean Classification Accuracy For Observations Assigned to Each MapUnit (MLR)", x="MapUnit", y = "Mean Classification Accuracy & 95% CI")+
   theme_classic() + theme(axis.text.x = element_text(angle = 90, vjust = .5, hjust=1))

```


## Lasso Multinomial Logistic Regression:


```{r,cache=TRUE,warning=FALSE}
mlr.las1=glmnet(data.matrix(Lavaflow2.X), Lavaflow2$MapUnit, family = "multinomial", type.multinomial = "ungrouped")
set.seed(17)
mlr.las1.cv = cv.glmnet(data.matrix(Lavaflow2.X), Lavaflow2$MapUnit, family = "multinomial", type.multinomial = "ungrouped")
```


```{r}
plot(mlr.las1,xvar = "lambda", label = TRUE, type.coef = "2norm")
abline(v=log(mlr.las1.cv$lambda.min))
#lambda.min is the value of lambda that gives the minimum (10 fold) cross-validated Multinomial Deviance 
plot(mlr.las1.cv)
```


```{r}
coef.las1=do.call(cbind,coef(mlr.las1.cv,s="lambda.min"))
colnames(coef.las1)=names(coef(mlr.las1.cv,s="lambda.min"))
barplot(height = apply(coef.las1!=0,FUN = mean,MARGIN = 1),ylab = "Percent Non-zero Coefficients",las=2)
sig.las1=data.frame(coef=as.vector(as.matrix(coef.las1)),variable=rep(rownames(coef.las1),times=ncol(coef.las1)),MapUnit=rep(colnames(coef.las1),each=nrow(coef.las1)))
sig.las1$significant=sig.las1$coef!=0
sig.las1$variable=factor(sig.las1$variable)
sig.las1$MapUnit=factor(sig.las1$MapUnit)
sig.las1$significant=factor(sig.las1$significant)
ggplot(sig.las1,aes(x=MapUnit,y=variable,fill=significant,color=significant))+geom_tile()+scale_fill_manual(values=c("white", "black"))+labs(title="Significant Variables by MapUnit (Lasso MLR)")+theme_classic() + theme(axis.text.x = element_text(angle = 90, vjust = .5, hjust=1))

```


```{r}
#Function for Repeated random sub-sampling cross-validation for classification using lasso multinomial logistic regression (repeated N.resamp times)

MLR.las.CV=function(data=Lavaflow2.X,groups=Lavaflow2$MapUnit,p.test=1/3,N.resamp=50){
  groups=factor(groups)
  confusion=vector(mode = "list",length=N.resamp)
  for (i in 1:N.resamp){
    test=slice_sample(group_by(data.frame(data,groups),groups),prop = p.test)
    train=anti_join(group_by(data.frame(data,groups),groups),test,by=names(test))
    train.x = data.matrix(as.data.frame(train[,names(train)%in%names(data)]))
    test.x = data.matrix(as.data.frame(test[,names(test)%in%names(data)]))
    train.g=train$groups
    test.g=test$groups
    mlr.las.s=cv.glmnet(train.x, train.g, family = "multinomial", type.multinomial = "ungrouped")
    predictions=predict(mlr.las.s, newx = test.x, s = "lambda.min", type = "class")
    predictions=factor(predictions,levels=levels(groups))
    confusion[[i]]=table(test.groups=test.g,predictions)
  }
  accuracy=sapply(confusion,function(x){sum(diag(x))/sum(x)})
  return(list("confusion.matrices"=confusion,"accuracy"=accuracy))
}
```


```{r,cache=TRUE,results='hide',message=FALSE,warning=FALSE}
set.seed(27)
mlr.cv2=MLR.las.CV(N.resamp = 50,p.test = 1/4)
```


```{r}
mlr.cv22=group.accuracy(mlr.cv2,transpose = FALSE)

 ggplot(mlr.cv22, aes(x=group, y=mean.accuracies)) + 
  geom_bar(stat="identity", color="black",fill="red",width = .8) +
  geom_errorbar(aes(ymin=q1, ymax=q2),width=.2)+geom_text(aes(x=group,y=mean.accuracies/2,label=round(mean.accuracies,2)))+geom_text(aes(x=group,y=-.05,label=c(table(Lavaflow2$MapUnit),sum(table(Lavaflow2$MapUnit)))))+labs(title="Mean Classification Accuracy For Observations in Each MapUnit (Lasso MLR)", x="MapUnit", y = "Mean Classification Accuracy & 95% CI")+
   theme_classic() + theme(axis.text.x = element_text(angle = 90, vjust = .5, hjust=1))

```


```{r}
mlr.cv22t=group.accuracy(mlr.cv2,transpose = TRUE)

 ggplot(mlr.cv22t, aes(x=group, y=mean.accuracies)) + 
  geom_bar(stat="identity", color="black",fill="red",width = .8) +
  geom_errorbar(aes(ymin=q1, ymax=q2),width=.2)+geom_text(aes(x=group,y=mean.accuracies/2,label=round(mean.accuracies,2)))+geom_text(aes(x=group,y=-.05,label=c(table(Lavaflow2$MapUnit),sum(table(Lavaflow2$MapUnit)))))+labs(title="Mean Classification Accuracy For Observations Assigned to Each MapUnit (Lasso MLR)", x="MapUnit", y = "Mean Classification Accuracy & 95% CI")+
   theme_classic() + theme(axis.text.x = element_text(angle = 90, vjust = .5, hjust=1))

```

## Lasso Multinomial Logistic Regression with Interaction:

```{r}
# We were told that the following ratios may be useful for classification: Ti/Zr, Sc/Cr, Ti/V, Ba/Nb, Ce/Nb, Zr/Nb, Ba/Sr, Rb/Sr, Zr/Y, Cr/P2O5, FeO*/MgO

#Making sure we don't divide by zero:
apply(Lavaflow2.X==0,MARGIN = 2,sum)

#Looks like only Ni has any zero values

Lavaflow2.X2=Lavaflow2.X
Lavaflow2.X2$Ti_Zr=Lavaflow2.X2$TiO2/Lavaflow2.X2$Zr
Lavaflow2.X2$Sc_Cr=Lavaflow2.X2$Sc/Lavaflow2.X2$Cr
Lavaflow2.X2$Ti_V=Lavaflow2.X2$TiO2/Lavaflow2.X2$V
Lavaflow2.X2$Ba_Nb=Lavaflow2.X2$Ba/Lavaflow2.X2$Nb
Lavaflow2.X2$Zr_Nb=Lavaflow2.X2$Zr/Lavaflow2.X2$Nb
Lavaflow2.X2$Ba_Sr=Lavaflow2.X2$Ba/Lavaflow2.X2$Sr
Lavaflow2.X2$Rb_Sr=Lavaflow2.X2$Rb/Lavaflow2.X2$Sr
Lavaflow2.X2$Zr_Y=Lavaflow2.X2$Zr/Lavaflow2.X2$Y
Lavaflow2.X2$Cr_P2O5=Lavaflow2.X2$Cr/Lavaflow2.X2$P2O5
Lavaflow2.X2$FeOt_MgO=Lavaflow2.X2$FeOt/Lavaflow2.X2$MgO


```


```{r,cache=TRUE,warning=FALSE}
mlr.las2=glmnet(data.matrix(Lavaflow2.X2), Lavaflow2$MapUnit, family = "multinomial", type.multinomial = "ungrouped")
set.seed(17)
mlr.las2.cv = cv.glmnet(data.matrix(Lavaflow2.X2), Lavaflow2$MapUnit, family = "multinomial", type.multinomial = "ungrouped")
```


```{r}
plot(mlr.las2,xvar = "lambda", label = TRUE, type.coef = "2norm")
abline(v=log(mlr.las2.cv$lambda.min))
#lambda.min is the value of lambda that gives the minimum (10 fold) cross-validated Multinomial Deviance 
plot(mlr.las2.cv)
```

```{r}
coef.las2=do.call(cbind,coef(mlr.las2.cv,s="lambda.min"))
colnames(coef.las2)=names(coef(mlr.las2.cv,s="lambda.min"))
barplot(height = apply(coef.las2!=0,FUN = mean,MARGIN = 1),ylab = "Percent Non-zero Coefficients",las=2)
sig.las2=data.frame(coef=as.vector(as.matrix(coef.las2)),variable=rep(rownames(coef.las2),times=ncol(coef.las2)),MapUnit=rep(colnames(coef.las2),each=nrow(coef.las2)))
sig.las2$significant=sig.las2$coef!=0
sig.las2$variable=factor(sig.las2$variable)
sig.las2$MapUnit=factor(sig.las2$MapUnit)
sig.las2$significant=factor(sig.las2$significant)
ggplot(sig.las2,aes(x=MapUnit,y=variable,fill=significant,color=significant))+geom_tile()+scale_fill_manual(values=c("white", "black"))+labs(title="Significant Variables by MapUnit (Lasso MLR w/Ratios)")+theme_classic() + theme(axis.text.x = element_text(angle = 90, vjust = .5, hjust=1))
```


```{r,cache=TRUE,results='hide',message=FALSE,warning=FALSE}
set.seed(27)
mlr.cv3=MLR.las.CV(N.resamp = 50,p.test = 1/4,data = Lavaflow2.X2)
```



```{r}
mlr.cv32=group.accuracy(mlr.cv3,transpose = FALSE)

 ggplot(mlr.cv32, aes(x=group, y=mean.accuracies)) + 
  geom_bar(stat="identity", color="black",fill="red",width = .8) +
  geom_errorbar(aes(ymin=q1, ymax=q2),width=.2)+geom_text(aes(x=group,y=mean.accuracies/2,label=round(mean.accuracies,2)))+geom_text(aes(x=group,y=-.05,label=c(table(Lavaflow2$MapUnit),sum(table(Lavaflow2$MapUnit)))))+labs(title="Mean Classification Accuracy For Observations in Each MapUnit (Lasso MLR w/Ratios)", x="MapUnit", y = "Mean Classification Accuracy & 95% CI")+
   theme_classic() + theme(axis.text.x = element_text(angle = 90, vjust = .5, hjust=1))

```



```{r}
mlr.cv32t=group.accuracy(mlr.cv3,transpose = TRUE)

 ggplot(mlr.cv32t, aes(x=group, y=mean.accuracies)) + 
  geom_bar(stat="identity", color="black",fill="red",width = .8) +
  geom_errorbar(aes(ymin=q1, ymax=q2),width=.2)+geom_text(aes(x=group,y=mean.accuracies/2,label=round(mean.accuracies,2)))+geom_text(aes(x=group,y=-.05,label=c(table(Lavaflow2$MapUnit),sum(table(Lavaflow2$MapUnit)))))+labs(title="Mean Classification Accuracy For Observations Assigned to Each MapUnit (Lasso MLR w/Ratios)", x="MapUnit", y = "Mean Classification Accuracy & 95% CI")+
   theme_classic() + theme(axis.text.x = element_text(angle = 90, vjust = .5, hjust=1))

```

## More Plots


```{r,include=FALSE}
#Mean Classification Accuracy For Observations in Each MapUnit:

 LDA_group_accuracy=ggplot(LDA15.samp2, aes(x=group, y=mean.accuracies)) + 
  geom_bar(stat="identity", color="black",fill="red",width = .8) +
  geom_errorbar(aes(ymin=q1, ymax=q2),width=.2)+geom_text(aes(x=group,y=mean.accuracies/2,label=round(mean.accuracies,2)))+geom_text(aes(x=group,y=-.05,label=c(table(Lavaflow2$MapUnit),sum(table(Lavaflow2$MapUnit)))))+labs(title="LDA", x="MapUnit", y = "Mean Classification Accuracy & 95% CI")+
   theme_classic() + theme(axis.text.x = element_text(angle = 90, vjust = .5, hjust=1))

 MLR_group_accuracy=ggplot(mlr.cv12, aes(x=group, y=mean.accuracies)) + 
  geom_bar(stat="identity", color="black",fill="red",width = .8) +
  geom_errorbar(aes(ymin=q1, ymax=q2),width=.2)+geom_text(aes(x=group,y=mean.accuracies/2,label=round(mean.accuracies,2)))+geom_text(aes(x=group,y=-.05,label=c(table(Lavaflow2$MapUnit),sum(table(Lavaflow2$MapUnit)))))+labs(title="MLR", x="MapUnit", y = "Mean Classification Accuracy & 95% CI")+
   theme_classic() + theme(axis.text.x = element_text(angle = 90, vjust = .5, hjust=1))

MLR_lasso_group_accuracy=ggplot(mlr.cv22, aes(x=group, y=mean.accuracies)) + 
  geom_bar(stat="identity", color="black",fill="red",width = .8) +
  geom_errorbar(aes(ymin=q1, ymax=q2),width=.2)+geom_text(aes(x=group,y=mean.accuracies/2,label=round(mean.accuracies,2)))+geom_text(aes(x=group,y=-.05,label=c(table(Lavaflow2$MapUnit),sum(table(Lavaflow2$MapUnit)))))+labs(title="Lasso MLR", x="MapUnit", y = "Mean Classification Accuracy & 95% CI")+
   theme_classic() + theme(axis.text.x = element_text(angle = 90, vjust = .5, hjust=1))

 MLR_lasso_w_int_group_accuracy=ggplot(mlr.cv32, aes(x=group, y=mean.accuracies)) + 
  geom_bar(stat="identity", color="black",fill="red",width = .8) +
  geom_errorbar(aes(ymin=q1, ymax=q2),width=.2)+geom_text(aes(x=group,y=mean.accuracies/2,label=round(mean.accuracies,2)))+geom_text(aes(x=group,y=-.05,label=c(table(Lavaflow2$MapUnit),sum(table(Lavaflow2$MapUnit)))))+labs(title="Lasso MLR w/Ratios", x="MapUnit", y = "Mean Classification Accuracy & 95% CI")+
   theme_classic() + theme(axis.text.x = element_text(angle = 90, vjust = .5, hjust=1))

```



```{r}
plot_grid(ggdraw()+draw_label("Classification Accuracy For Observations in Each MapUnit",fontface = "bold"),plot_grid(LDA_group_accuracy,MLR_group_accuracy,ncol = 2),plot_grid(MLR_lasso_group_accuracy,MLR_lasso_w_int_group_accuracy,ncol = 2),nrow = 3,rel_heights = c(.2,1,1))
```


```{r,include=FALSE}
#Mean Classification Accuracy For Observations Assigned to Each MapUnit:

 LDA_group_accuracy_t=ggplot(LDA15.samp2t, aes(x=group, y=mean.accuracies)) + 
  geom_bar(stat="identity", color="black",fill="red",width = .8) +
  geom_errorbar(aes(ymin=q1, ymax=q2),width=.2)+geom_text(aes(x=group,y=mean.accuracies/2,label=round(mean.accuracies,2)))+geom_text(aes(x=group,y=-.05,label=c(table(Lavaflow2$MapUnit),sum(table(Lavaflow2$MapUnit)))))+labs(title="LDA", x="MapUnit", y = "Mean Classification Accuracy & 95% CI")+
   theme_classic() + theme(axis.text.x = element_text(angle = 90, vjust = .5, hjust=1))

 MLR_group_accuracy_t=ggplot(mlr.cv12t, aes(x=group, y=mean.accuracies)) + 
  geom_bar(stat="identity", color="black",fill="red",width = .8) +
  geom_errorbar(aes(ymin=q1, ymax=q2),width=.2)+geom_text(aes(x=group,y=mean.accuracies/2,label=round(mean.accuracies,2)))+geom_text(aes(x=group,y=-.05,label=c(table(Lavaflow2$MapUnit),sum(table(Lavaflow2$MapUnit)))))+labs(title="MLR", x="MapUnit", y = "Mean Classification Accuracy & 95% CI")+
   theme_classic() + theme(axis.text.x = element_text(angle = 90, vjust = .5, hjust=1))

MLR_lasso_group_accuracy_t=ggplot(mlr.cv22t, aes(x=group, y=mean.accuracies)) + 
  geom_bar(stat="identity", color="black",fill="red",width = .8) +
  geom_errorbar(aes(ymin=q1, ymax=q2),width=.2)+geom_text(aes(x=group,y=mean.accuracies/2,label=round(mean.accuracies,2)))+geom_text(aes(x=group,y=-.05,label=c(table(Lavaflow2$MapUnit),sum(table(Lavaflow2$MapUnit)))))+labs(title="Lasso MLR", x="MapUnit", y = "Mean Classification Accuracy & 95% CI")+
   theme_classic() + theme(axis.text.x = element_text(angle = 90, vjust = .5, hjust=1))

 MLR_lasso_w_int_group_accuracy_t=ggplot(mlr.cv32t, aes(x=group, y=mean.accuracies)) + 
  geom_bar(stat="identity", color="black",fill="red",width = .8) +
  geom_errorbar(aes(ymin=q1, ymax=q2),width=.2)+geom_text(aes(x=group,y=mean.accuracies/2,label=round(mean.accuracies,2)))+geom_text(aes(x=group,y=-.05,label=c(table(Lavaflow2$MapUnit),sum(table(Lavaflow2$MapUnit)))))+labs(title="Lasso MLR w/Ratios", x="MapUnit", y = "Mean Classification Accuracy & 95% CI")+
   theme_classic() + theme(axis.text.x = element_text(angle = 90, vjust = .5, hjust=1))

```



```{r}
plot_grid(ggdraw()+draw_label("Classification Accuracy For Observations Assigned to Each MapUnit",fontface = "bold"),plot_grid(LDA_group_accuracy_t,MLR_group_accuracy_t,ncol = 2),plot_grid(MLR_lasso_group_accuracy_t,MLR_lasso_w_int_group_accuracy_t,ncol = 2),nrow = 3,rel_heights = c(.2,1,1))
```

## Multicolinearity Diagnostics


```{r}
cor.X=cor(Lavaflow2.X)
c22.2=combn(22,2)
cor.X.order=data.frame(variables=paste(colnames(cor.X)[c22.2[1,]],colnames(cor.X)[c22.2[2,]],sep = ","),correlation=cor.X[t(c22.2)])
cor.X.order=cor.X.order[order(abs(cor.X.order$correlation),decreasing = TRUE),]
cor.X.order$correlation=round(cor.X.order$correlation,3)
cor.X.order[1:10,]
```


```{r}
e.X=eigen(cor(Lavaflow2.X))
Condition.Ind.X=e.X$values[1]/e.X$values
round(Condition.Ind.X,3)
Condition.Num.X=Condition.Ind.X[length(Condition.Ind.X)]
round(Condition.Num.X,3)
```
